{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 80000\n",
    "DIGITS = 3\n",
    "REVERSE = False\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "chars = '0123456789- '\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    def __init__(self, chars):\n",
    "        self.chars = sorted(set(chars)) # [' ', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars)) # {' ': 0, '-': 1, '0': 2, ... , '9': 11}\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars)) # {0: ' ', 1: '-', 2: '0',..., 11: '9'}\n",
    "    \n",
    "    def encode(self, C, num_rows):\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[i] for i in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 80000\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    # f函數：隨機產生一個1位數到3位數之間的整數（DIGIT==3）\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789')) for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    key = tuple(sorted((a, b), reverse=True)) # 將a, b由小到大排序並轉成tuple\n",
    "    a, b = key[0], key[1]\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    q = '{}-{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q)) # 將query長度補足到7，MAXLEN最長等於7(當DIGIT等於3)\n",
    "    ans = str(a - b)\n",
    "    ans += ' ' * (DIGITS - len(ans)) # 將ans長度補足到3，兩個三位數相減最多是三位數\n",
    "    if REVERSE:\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['130-4  ', '849-6  ', '759-61 ', '85-67  ', '17-12  '] ['126', '843', '698', '18 ', '5  ']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5], expected[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "# x總共有80000筆資料，每筆資料shape是7x12，7代表問題長度為7，並且每個位數的值有12種可能\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool) # x.shape = (80000, 7, 12)\n",
    "y = np.zeros((len(expected), DIGITS, len(chars)), dtype=np.bool) # y.shape = (80000, 3, 12)\n",
    "\n",
    "# 將問題與解答編碼成一個一個的二維陣列\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(54000, 7, 12)\n",
      "(54000, 3, 12)\n",
      "Validation Data:\n",
      "(6000, 7, 12)\n",
      "(6000, 3, 12)\n",
      "Testing Data:\n",
      "(20000, 7, 12)\n",
      "(20000, 3, 12)\n"
     ]
    }
   ],
   "source": [
    "# 將80000筆資料打亂順序\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# train_test_split\n",
    "train_x = x[:60000]\n",
    "train_y = y[:60000]\n",
    "test_x = x[60000:]\n",
    "test_y = y[60000:]\n",
    "\n",
    "split_at = len(train_x) - len(train_x) // 10\n",
    "(x_train, x_val) = train_x[:split_at], train_x[split_at:]\n",
    "(y_train, y_val) = train_y[:split_at], train_y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print('Testing Data:')\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "\n",
    "https://blog.csdn.net/ChaoFeiLi/article/details/89323078"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildOneToOneModel(shape):\n",
    "    model = Sequential()\n",
    "    model.add(layers.LSTM(128, input_shape=(shape[1], shape[2])))\n",
    "    model.add(layers.RepeatVector(3))\n",
    "    model.add(layers.LSTM(64, return_sequences=True))\n",
    "    model.add(layers.LSTM(64, return_sequences=True))\n",
    "    model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From /home/shihyu/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 3, 64)             49408     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 3, 64)             33024     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 3, 12)             780       \n",
      "=================================================================\n",
      "Total params: 155,404\n",
      "Trainable params: 155,404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = buildOneToOneModel(x_train.shape)\n",
    "#model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_y = []\n",
    "for i in range(20000):\n",
    "    decode_y.append(ctable.decode(test_y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 0\n",
      "WARNING:tensorflow:From /home/shihyu/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 40s 732us/step - loss: 0.0740 - acc: 0.1445 - val_loss: 0.0705 - val_acc: 0.1977\n",
      "Q 590-560 T 30  \u001b[91m☒\u001b[0m 11 \n",
      "Q 932-787 T 145 \u001b[91m☒\u001b[0m 311\n",
      "Q 587-9   T 578 \u001b[91m☒\u001b[0m 671\n",
      "Q 554-31  T 523 \u001b[91m☒\u001b[0m 436\n",
      "Q 348-14  T 334 \u001b[91m☒\u001b[0m 333\n",
      "Q 95-13   T 82  \u001b[91m☒\u001b[0m 11 \n",
      "Q 122-0   T 122 \u001b[91m☒\u001b[0m 11 \n",
      "Q 861-70  T 791 \u001b[91m☒\u001b[0m 667\n",
      "Q 644-11  T 633 \u001b[91m☒\u001b[0m 433\n",
      "Q 781-58  T 723 \u001b[91m☒\u001b[0m 661\n",
      "Accuracy on Testing Data: 0.003\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 32s 587us/step - loss: 0.0660 - acc: 0.2696 - val_loss: 0.0621 - val_acc: 0.3133\n",
      "Accuracy on Testing Data: 0.008\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 29s 545us/step - loss: 0.0602 - acc: 0.3317 - val_loss: 0.0577 - val_acc: 0.3583\n",
      "Accuracy on Testing Data: 0.011\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 29s 542us/step - loss: 0.0566 - acc: 0.3742 - val_loss: 0.0549 - val_acc: 0.3954\n",
      "Accuracy on Testing Data: 0.015\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 29s 542us/step - loss: 0.0539 - acc: 0.4066 - val_loss: 0.0524 - val_acc: 0.4157\n",
      "Accuracy on Testing Data: 0.019\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 29s 543us/step - loss: 0.0517 - acc: 0.4302 - val_loss: 0.0506 - val_acc: 0.4361\n",
      "Accuracy on Testing Data: 0.024\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 29s 543us/step - loss: 0.0503 - acc: 0.4460 - val_loss: 0.0493 - val_acc: 0.4563\n",
      "Accuracy on Testing Data: 0.028\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 34s 626us/step - loss: 0.0484 - acc: 0.4693 - val_loss: 0.0469 - val_acc: 0.4888\n",
      "Accuracy on Testing Data: 0.036\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 38s 701us/step - loss: 0.0469 - acc: 0.4864 - val_loss: 0.0474 - val_acc: 0.4719\n",
      "Accuracy on Testing Data: 0.038\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 42s 773us/step - loss: 0.0457 - acc: 0.5013 - val_loss: 0.0450 - val_acc: 0.5144\n",
      "Accuracy on Testing Data: 0.044\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 41s 760us/step - loss: 0.0446 - acc: 0.5168 - val_loss: 0.0443 - val_acc: 0.5222\n",
      "Accuracy on Testing Data: 0.045\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 46s 855us/step - loss: 0.0432 - acc: 0.5322 - val_loss: 0.0426 - val_acc: 0.5364\n",
      "Accuracy on Testing Data: 0.047\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 47s 865us/step - loss: 0.0421 - acc: 0.5446 - val_loss: 0.0418 - val_acc: 0.5460\n",
      "Accuracy on Testing Data: 0.055\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 45s 836us/step - loss: 0.0411 - acc: 0.5553 - val_loss: 0.0402 - val_acc: 0.5610\n",
      "Accuracy on Testing Data: 0.06\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 44s 807us/step - loss: 0.0402 - acc: 0.5655 - val_loss: 0.0395 - val_acc: 0.5686\n",
      "Accuracy on Testing Data: 0.065\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 36s 663us/step - loss: 0.0398 - acc: 0.5687 - val_loss: 0.0388 - val_acc: 0.5762\n",
      "Accuracy on Testing Data: 0.057\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 44s 809us/step - loss: 0.0391 - acc: 0.5761 - val_loss: 0.0391 - val_acc: 0.5739\n",
      "Accuracy on Testing Data: 0.059\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 33s 614us/step - loss: 0.0381 - acc: 0.5871 - val_loss: 0.0382 - val_acc: 0.5845\n",
      "Accuracy on Testing Data: 0.072\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 34s 630us/step - loss: 0.0377 - acc: 0.5909 - val_loss: 0.0395 - val_acc: 0.5684\n",
      "Accuracy on Testing Data: 0.059\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 34s 632us/step - loss: 0.0368 - acc: 0.6012 - val_loss: 0.0365 - val_acc: 0.6010\n",
      "Accuracy on Testing Data: 0.074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 33s 605us/step - loss: 0.0362 - acc: 0.6072 - val_loss: 0.0365 - val_acc: 0.5981\n",
      "Accuracy on Testing Data: 0.074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 32s 601us/step - loss: 0.0359 - acc: 0.6107 - val_loss: 0.0364 - val_acc: 0.6051\n",
      "Accuracy on Testing Data: 0.073\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 33s 611us/step - loss: 0.0353 - acc: 0.6168 - val_loss: 0.0354 - val_acc: 0.6163\n",
      "Accuracy on Testing Data: 0.082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 35s 644us/step - loss: 0.0350 - acc: 0.6209 - val_loss: 0.0350 - val_acc: 0.6205\n",
      "Accuracy on Testing Data: 0.075\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 38s 709us/step - loss: 0.0343 - acc: 0.6273 - val_loss: 0.0346 - val_acc: 0.6221\n",
      "Accuracy on Testing Data: 0.083\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 45s 831us/step - loss: 0.0338 - acc: 0.6342 - val_loss: 0.0354 - val_acc: 0.6154\n",
      "Accuracy on Testing Data: 0.082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 49s 910us/step - loss: 0.0337 - acc: 0.6354 - val_loss: 0.0337 - val_acc: 0.6279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Testing Data: 0.087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 40s 740us/step - loss: 0.0331 - acc: 0.6418 - val_loss: 0.0335 - val_acc: 0.6318\n",
      "Accuracy on Testing Data: 0.089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 44s 816us/step - loss: 0.0329 - acc: 0.6437 - val_loss: 0.0333 - val_acc: 0.6362\n",
      "Accuracy on Testing Data: 0.089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 45s 840us/step - loss: 0.0328 - acc: 0.6460 - val_loss: 0.0322 - val_acc: 0.6462\n",
      "Accuracy on Testing Data: 0.1\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 36s 665us/step - loss: 0.0322 - acc: 0.6525 - val_loss: 0.0328 - val_acc: 0.6403\n",
      "Accuracy on Testing Data: 0.102\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 35s 643us/step - loss: 0.0318 - acc: 0.6566 - val_loss: 0.0325 - val_acc: 0.6436\n",
      "Accuracy on Testing Data: 0.107\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 36s 662us/step - loss: 0.0315 - acc: 0.6603 - val_loss: 0.0322 - val_acc: 0.6511\n",
      "Accuracy on Testing Data: 0.108\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 32s 597us/step - loss: 0.0312 - acc: 0.6649 - val_loss: 0.0325 - val_acc: 0.6457\n",
      "Accuracy on Testing Data: 0.109\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 44s 822us/step - loss: 0.0308 - acc: 0.6689 - val_loss: 0.0310 - val_acc: 0.6621\n",
      "Accuracy on Testing Data: 0.13\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 42s 775us/step - loss: 0.0305 - acc: 0.6730 - val_loss: 0.0308 - val_acc: 0.6679\n",
      "Accuracy on Testing Data: 0.135\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 40s 746us/step - loss: 0.0303 - acc: 0.6767 - val_loss: 0.0306 - val_acc: 0.6678\n",
      "Accuracy on Testing Data: 0.139\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 44s 809us/step - loss: 0.0296 - acc: 0.6845 - val_loss: 0.0299 - val_acc: 0.6768\n",
      "Accuracy on Testing Data: 0.146\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 42s 774us/step - loss: 0.0292 - acc: 0.6914 - val_loss: 0.0301 - val_acc: 0.6799\n",
      "Accuracy on Testing Data: 0.163\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 40s 740us/step - loss: 0.0289 - acc: 0.6972 - val_loss: 0.0294 - val_acc: 0.6882\n",
      "Accuracy on Testing Data: 0.178\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 42s 769us/step - loss: 0.0279 - acc: 0.7087 - val_loss: 0.0287 - val_acc: 0.6972\n",
      "Accuracy on Testing Data: 0.199\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 42s 775us/step - loss: 0.0273 - acc: 0.7204 - val_loss: 0.0290 - val_acc: 0.7051\n",
      "Accuracy on Testing Data: 0.231\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 45s 839us/step - loss: 0.0263 - acc: 0.7357 - val_loss: 0.0265 - val_acc: 0.7343\n",
      "Accuracy on Testing Data: 0.297\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 42s 769us/step - loss: 0.0247 - acc: 0.7593 - val_loss: 0.0252 - val_acc: 0.7600\n",
      "Accuracy on Testing Data: 0.368\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 46s 860us/step - loss: 0.0225 - acc: 0.7905 - val_loss: 0.0230 - val_acc: 0.7866\n",
      "Accuracy on Testing Data: 0.448\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 49s 904us/step - loss: 0.0199 - acc: 0.8246 - val_loss: 0.0196 - val_acc: 0.8298\n",
      "Accuracy on Testing Data: 0.564\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 41s 752us/step - loss: 0.0163 - acc: 0.8644 - val_loss: 0.0157 - val_acc: 0.8707\n",
      "Accuracy on Testing Data: 0.668\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 40s 749us/step - loss: 0.0133 - acc: 0.8940 - val_loss: 0.0131 - val_acc: 0.8942\n",
      "Accuracy on Testing Data: 0.73\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 41s 752us/step - loss: 0.0109 - acc: 0.9156 - val_loss: 0.0111 - val_acc: 0.9114\n",
      "Accuracy on Testing Data: 0.781\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 41s 752us/step - loss: 0.0089 - acc: 0.9322 - val_loss: 0.0092 - val_acc: 0.9274\n",
      "Accuracy on Testing Data: 0.822\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 46s 848us/step - loss: 0.0077 - acc: 0.9423 - val_loss: 0.0081 - val_acc: 0.9359\n",
      "Accuracy on Testing Data: 0.83\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 48s 884us/step - loss: 0.0069 - acc: 0.9486 - val_loss: 0.0069 - val_acc: 0.9484\n",
      "Accuracy on Testing Data: 0.864\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 45s 830us/step - loss: 0.0059 - acc: 0.9573 - val_loss: 0.0072 - val_acc: 0.9443\n",
      "Accuracy on Testing Data: 0.855\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 44s 821us/step - loss: 0.0056 - acc: 0.9588 - val_loss: 0.0076 - val_acc: 0.9399\n",
      "Accuracy on Testing Data: 0.838\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 38s 701us/step - loss: 0.0052 - acc: 0.9625 - val_loss: 0.0059 - val_acc: 0.9551\n",
      "Accuracy on Testing Data: 0.885\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 53s 982us/step - loss: 0.0048 - acc: 0.9655 - val_loss: 0.0054 - val_acc: 0.9604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Testing Data: 0.891\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 39s 719us/step - loss: 0.0043 - acc: 0.9700 - val_loss: 0.0047 - val_acc: 0.9655\n",
      "Accuracy on Testing Data: 0.906\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 38s 711us/step - loss: 0.0042 - acc: 0.9696 - val_loss: 0.0047 - val_acc: 0.9654\n",
      "Accuracy on Testing Data: 0.903\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 36s 668us/step - loss: 0.0041 - acc: 0.9709 - val_loss: 0.0055 - val_acc: 0.9577\n",
      "Accuracy on Testing Data: 0.883\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 35s 643us/step - loss: 0.0036 - acc: 0.9751 - val_loss: 0.0038 - val_acc: 0.9720\n",
      "Accuracy on Testing Data: 0.925\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 60\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 36s 674us/step - loss: 0.0032 - acc: 0.9780 - val_loss: 0.0041 - val_acc: 0.9688\n",
      "Accuracy on Testing Data: 0.914\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 61\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 35s 650us/step - loss: 0.0034 - acc: 0.9768 - val_loss: 0.0047 - val_acc: 0.9649\n",
      "Accuracy on Testing Data: 0.901\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 62\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 41s 763us/step - loss: 0.0032 - acc: 0.9779 - val_loss: 0.0037 - val_acc: 0.9735\n",
      "Accuracy on Testing Data: 0.928\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 63\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 45s 828us/step - loss: 0.0027 - acc: 0.9818 - val_loss: 0.0039 - val_acc: 0.9721\n",
      "Accuracy on Testing Data: 0.928\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 64\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 49s 899us/step - loss: 0.0029 - acc: 0.9800 - val_loss: 0.0034 - val_acc: 0.9757\n",
      "Accuracy on Testing Data: 0.935\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 65\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 41s 758us/step - loss: 0.0028 - acc: 0.9813 - val_loss: 0.0038 - val_acc: 0.9722\n",
      "Accuracy on Testing Data: 0.922\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 66\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 40s 746us/step - loss: 0.0024 - acc: 0.9842 - val_loss: 0.0036 - val_acc: 0.9749\n",
      "Accuracy on Testing Data: 0.929\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 67\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 33s 615us/step - loss: 0.0026 - acc: 0.9822 - val_loss: 0.0031 - val_acc: 0.9775\n",
      "Accuracy on Testing Data: 0.934\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 68\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 39s 720us/step - loss: 0.0023 - acc: 0.9849 - val_loss: 0.0029 - val_acc: 0.9798\n",
      "Accuracy on Testing Data: 0.937\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 69\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 34s 626us/step - loss: 0.0022 - acc: 0.9857 - val_loss: 0.0029 - val_acc: 0.9799\n",
      "Accuracy on Testing Data: 0.947\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 70\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 34s 633us/step - loss: 0.0021 - acc: 0.9865 - val_loss: 0.0032 - val_acc: 0.9764\n",
      "Accuracy on Testing Data: 0.935\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 71\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 36s 662us/step - loss: 0.0022 - acc: 0.9851 - val_loss: 0.0039 - val_acc: 0.9706\n",
      "Accuracy on Testing Data: 0.921\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 72\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 36s 664us/step - loss: 0.0018 - acc: 0.9886 - val_loss: 0.0020 - val_acc: 0.9872\n",
      "Accuracy on Testing Data: 0.962\n",
      "Q 990-807 T 183 \u001b[92m☑\u001b[0m 183\n",
      "Q 356-36  T 320 \u001b[92m☑\u001b[0m 320\n",
      "Q 836-238 T 598 \u001b[91m☒\u001b[0m 698\n",
      "Q 88-9    T 79  \u001b[92m☑\u001b[0m 79 \n",
      "Q 949-89  T 860 \u001b[92m☑\u001b[0m 860\n",
      "Q 613-45  T 568 \u001b[92m☑\u001b[0m 568\n",
      "Q 516-6   T 510 \u001b[92m☑\u001b[0m 510\n",
      "Q 184-74  T 110 \u001b[92m☑\u001b[0m 110\n",
      "Q 147-26  T 121 \u001b[92m☑\u001b[0m 121\n",
      "Q 887-5   T 882 \u001b[92m☑\u001b[0m 882\n"
     ]
    }
   ],
   "source": [
    "epoch_prediction = []\n",
    "def first_ten():\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)\n",
    "        \n",
    "for iteration in range(100):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    if iteration == 0:\n",
    "        first_ten()\n",
    "    pred = model.predict(test_x)\n",
    "    correct = 0\n",
    "    for i in range(20000):\n",
    "        if ctable.decode(pred[i]) == decode_y[i]:\n",
    "            correct += 1\n",
    "    acc = round(correct/20000, 3)\n",
    "    print('Accuracy on Testing Data:',acc)\n",
    "    epoch_prediction.append(acc)\n",
    "    if acc >= 0.95:\n",
    "        first_ten()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/sub_pred.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(epoch_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSG : Prediction\n",
      "20000/20000 [==============================] - 7s 361us/step\n",
      "test cost: [0.001927267370847403, 0.9870833414793014]\n"
     ]
    }
   ],
   "source": [
    "print(\"MSG : Prediction\")\n",
    "cost = model.evaluate(test_x, test_y, batch_size=40)\n",
    "print(\"test cost: {}\".format(cost))\n",
    "pred = model.predict(test_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 testing data:\n",
      "Prediction\tAnswer\n",
      "278\t\t278\n",
      "348\t\t348\n",
      "119\t\t119\n",
      "429\t\t429\n",
      "550\t\t550\n",
      "107\t\t107\n",
      "679\t\t679\n",
      "377\t\t377\n",
      "85 \t\t85 \n",
      "434\t\t434\n",
      "------------------------------\n",
      "Prediction Accuracy: 0.962\n"
     ]
    }
   ],
   "source": [
    "print('First 10 testing data:')\n",
    "print('Prediction\\tAnswer')\n",
    "for i in range(10):\n",
    "    print(ctable.decode(pred[i]), end='\\t\\t')\n",
    "    print(ctable.decode(test_y[i]))\n",
    "\n",
    "print('-'*30)\n",
    "correct = 0\n",
    "for i in range(20000):\n",
    "    if ctable.decode(pred[i]) == ctable.decode(test_y[i]):\n",
    "        correct += 1\n",
    "print('Prediction Accuracy: {:.3f}'.format(correct/20000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- Training data: 54000\n",
    "- Validation data: 6000\n",
    "- Testing data: 20000\n",
    "- digit: 3\n",
    "\n",
    "Result: At epoch 72, reach testing data accuracy = 0.962<br>\n",
    "Compare to addition, subtraction operation takes more time to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('output/sub_pred.csv', newline='') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "         sub = [float(j) for j in row]\n",
    "with open('output/ex1.csv', newline='') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "         add = [float(j) for j in row]\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,80])\n",
    "axes.set_ylim([0,1])\n",
    "plt.plot(add, label='Addition')\n",
    "plt.plot(sub, label='Subtraction')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[從零開始的 Sequence to Sequence](http://zake7749.github.io/2017/09/28/Sequence-to-Sequence-tutorial/)<br>\n",
    "[如何在長短期記憶(LSTM)網絡中利用TimeDistributed層——python語言](https://kknews.cc/zh-tw/tech/y62kj5k.html)<br>\n",
    "[如何為LSTM重新構建輸入資料（Keras）](http://toments.com/179540/)<br>\n",
    "[Understanding Input and Output shapes in LSTM | Keras](https://medium.com/@shivajbd/understanding-input-and-output-shape-in-lstm-keras-c501ee95c65e)<br>\n",
    "[利用Keras建構LSTM模型，以Stock Prediction 為例 1](https://medium.com/@daniel820710/%E5%88%A9%E7%94%A8keras%E5%BB%BA%E6%A7%8Blstm%E6%A8%A1%E5%9E%8B-%E4%BB%A5stock-prediction-%E7%82%BA%E4%BE%8B-1-67456e0a0b)<br>\n",
    "[A ten-minute introduction to sequence-to-sequence learning in Keras](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)<br>\n",
    "[addition_rnn.py | Github](https://github.com/keras-team/keras/blob/master/examples/addition_rnn.py)<br>\n",
    "[Many to one and many to many LSTM examples in Keras](https://stackoverflow.com/questions/43034960/many-to-one-and-many-to-many-lstm-examples-in-keras)<br>\n",
    "[使用 Keras 实现简单的 Sequence to Sequence 模型](http://www.zmonster.me/2016/05/29/sequence_to_sequence_with_keras.html)<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
